# Description of Decision Forest Dialect

## Dialect
The dialect is called decisionforest (see src/include/Ops.td). The subsequent sections describe its contents.

## Types
* **TreeNode Type:** The node type contains the type of the feature index.
    * **Numerical TreeNode Type:** Is a subclass of the TreeNode type. Specifies that the node is a numerical node. Additionally, has the type of the threshold.
    * **Leaf type:** Is a subclass of the TreeNode type. Specifies that a node is a leaf. Has the type of the prediction.
    * **Categorical TreeNode Type:** (Currently unimplemented) Specifies the node computes a predicate on a categorical feature.
* **Tree Type:** Specifies general properties of the decision tree. Currently only has the return type of the tree (the type of the prediction). 
    * TODO We currently assume that all nodes in a tree have the same feature index and threshold type. Should the tree type just contain those details?
* **Tree Ensemble Type:** Contains details of the full forest. Currently has the return type, number of trees, the input type and the reduction type.

## Attributes
* **Decision Forest Attribute:** An attribute that contains all the trees in the forest being compiled. See DecisionForestAttribute in src/mlir/DecisionTreeAttributes.h. Additionally contains all information like node probabilities and conditional probabilities. 
* **Decision Tree Attribute:** Attribute that contains a single decision tree in the forest being compiled. See DecisionTreeAttribute (yet to be completed) in src/mlir/DecisionTreeAttributes.h.

## Operations
### High-level IR
The high-level IR that is generated from the JSON representation of the decision forest model only uses a single MLIR op and a single MLIR attribute. These are as follows:
* **Decision Forest Attribute:** This attribute contains all the details of the model constructed from the input JSON file. It contains a list of trees and details like the reduction type, the return type etc. See DecisionForestAttribute in src/mlir/DecisionTreeAttributes.h for the attribute definition and DecisionForest in src/include/DecisionForest.h for the class that stores the actual forest. 
* **Predict Decision Forest Op:** (See PredictForestOp in src/include/Ops.td) This operation takes a tensor argument (a set of rows for which inference needs to be performed) and returns a tensor (the predictions). It has an attribute of type DecisionForestAttribute which represents the model that we need to run inference on.
The MLIR code generated by the JSON parser contains a single function that has a single predict op. The following listing shows the MLIR code for a batch size of 16 on a model that has 1000 trees and an input with 8 features of type f64. 
```C++
builtin.module @MyModule  {
  builtin.func @Prediction_Function(%arg0: tensor<16x8xf64>) -> tensor<16xf64> {
    %0 = "decisionforest.predict_ensemble"(%arg0) {ensemble = #decisionforest<"ReductionType = 0, #Trees = 1000, resultType = tensor<16xf64>">} : (tensor<16x8xf64>) -> tensor<16xf64>
    "decisionforest.return"(%0) : (tensor<16xf64>) -> ()
  }
}
```
### Mid-level IR
The high-level IR described above is lowered to a mid-level IR to enable optimizations such as pipelining, vectorization, tiling etc. The mid-level IR has two main components -- operations to explicity represent tree and sub-tree traversals and attributes that represent trees in the model. The optimizer will optimize the computation by rewriting the operations while simultaneously using the attributes to perform layout optimizations on the trees. 

* **Operations**
   * **Loops:** For and while loops.
   * **Conditionals:** Ifs and predicates (TODO Do we need predication?). 
   * **Scalar operations:** Needed for reductions (+, *, max, min, voting etc.).
   * **TraverseTreeTile(Tree T, Node \*nodePtr, RowType x) \<Attrs : int TileSize\>:** Traverse the tile of size TileSize starting at nodePtr belonging to Tree T and return the resulting node pointer. Maps (Tree, Node\*, RowType) -> Node\*.
   * **TraverseTileForFixedTree(Node \*nodePtr, RowType x) \<Attre : Tree T, int TileSize\>:** Traverse the tile of size TileSize starting at nodePtr belonging to Tree T and return the resulting node pointer. Maps (Node\*, RowType) -> Node\*. This is different than the previous op because the tree is fixed in this op and it can only perform traversals on T. 
   * **SIMDContainer(VarArgs\<Traverse\>):** Used to represent vectorization. Contains several Traverse ops that are to be executed in a SIMD fashion.
   * **PipelineContainer(VarArgs\<Traverse\>):** Used to represent software pipelining between several Traverse ops. The load, compute, update stages of the contained Traverse ops are interleaved.
   * **IsLeaf:** Determine whether the argument is a leaf. Maps a Node pointer -> bool. 

* **Attributes**
   * This level of the IR contains the same attributes as the high level IR. However, the optimizer will add additional details such as tiling for trees. These details on the attributes will decide the concrete implementations of the Ops above (For example, how a tree tile is to be read etc).
### Low-level 
